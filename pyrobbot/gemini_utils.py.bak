"""Utilities for interacting with Google's Gemini API."""

import os
from typing import Any, Dict, List, Optional

import google.generativeai as genai
from google.generativeai.types import SafetySettingDict

def initialize_gemini(api_key: Optional[str] = None) -> None:
    """Initialize the Gemini API with the provided API key."""
    if api_key is None:
        api_key = os.getenv('GOOGLE_API_KEY')
    if not api_key:
        raise ValueError("No Gemini API key provided")
    
    # Configure the Gemini API
    genai.configure(api_key=api_key)
    
    # Make sure the model is available
    try:
        model = genai.GenerativeModel('gemini-pro')
        chat = model.start_chat()
        # Test the connection
        response = chat.send_message("test")
        if not response:
            raise ValueError("Failed to get response from Gemini API")
    except Exception as e:
        raise ValueError(f"Failed to initialize Gemini API: {str(e)}")
    
    # Make sure the model is available
    try:
        model = genai.GenerativeModel('gemini-pro')
        chat = model.start_chat()
        chat.send_message("test")  # Test the connection
    except Exception as e:
        raise ValueError(f"Failed to initialize Gemini API: {str(e)}") interacting with Google's Gemini API."""

import os
from typing import Any, Dict, List, Optional

import google.generativeai as genai
from google.generativeai.types import SafetySettingDict

def initialize_gemini(api_key: Optional[str] = None) -> None:
    """Initialize the Gemini API with the provided API key."""
    if api_key is None:
        api_key = os.getenv('GOOGLE_API_KEY')
    if not api_key:
        raise ValueError("No Gemini API key provided. Set GOOGLE_API_KEY environment variable.")
    
    genai.configure(api_key=api_key)

def get_gemini_chat(
    model: str = "gemini-pro",
    temperature: float = 0.7,
    top_p: float = 0.8,
    top_k: int = 40,
    max_output_tokens: int = 2048,
    safety_settings: Optional[List[SafetySettingDict]] = None,
) -> Any:
    """Create and return a Gemini chat instance with the specified parameters."""
    try:
        model = genai.GenerativeModel(
            model_name=model,
            generation_config={
                "temperature": temperature,
                "top_p": top_p,
                "top_k": top_k,
                "max_output_tokens": max_output_tokens,
            },
            safety_settings=safety_settings,
        )
        return model.start_chat(history=[])
    except Exception as e:
        raise Exception(f"Failed to create Gemini chat instance: {str(e)}")

def get_chat_response(
    chat: Any, 
    message: str,
    stream: bool = False
) -> str:
    """Get a response from the Gemini chat instance."""
    try:
        response = chat.send_message(
            message,
            stream=stream
        )
        if stream:
            collected_response = []
            for chunk in response:
                if chunk.text:
                    collected_response.append(chunk.text)
            return "".join(collected_response)
        return response.text
    except Exception as e:
        raise Exception(f"Failed to get chat response: {str(e)}")

def count_tokens(text: str) -> int:
    """Count the number of tokens in the given text using Gemini's tokenizer."""
    # Note: Gemini doesn't provide a direct token counting method
    # This is a rough estimate based on words
    return len(text.split())

def estimate_cost(input_tokens: int, output_tokens: int) -> float:
    """Estimate the cost of the API call based on token usage."""
    # Gemini Pro pricing (as of 2024):
    # Input: $0.00025 per 1K tokens
    # Output: $0.0005 per 1K tokens
    input_cost = (input_tokens / 1000) * 0.00025
    output_cost = (output_tokens / 1000) * 0.0005
    return input_cost + output_cost